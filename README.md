Unified Sales Analytics Lakehouse
ğŸ“Š Unified Sales Analytics â€“ End-to-End Data Engineering Lakehouse

Real-time ingestion â†’ Delta Lake â†’ Spark ETL â†’ Airflow orchestration â†’ Postgres DW â†’ Grafana dashboards


Overview
Unified Sales Analytics is a complete, production-grade Data Engineering pipeline built locally using:
Apache Kafka â€“ Real-time event ingestion
Apache Spark (Batch & Streaming) â€“ Processing & transformations
Delta Lake â€“ Bronze / Silver / Gold architecture
Apache Airflow â€“ Orchestration
PostgreSQL â€“ Data Warehouse
Grafana â€“ Dashboards & KPIs
The system simulates real e-commerce sales events and transforms them into business-ready metrics such as:
Daily Gross Revenue
Total Orders
Average Order Value
This is a fully functional lakehouse project designed to demonstrate real industry workflows.

How to Run the Project

1ï¸âƒ£ Create project environment
cd unified-sales-analytics
python3.11 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt

2ï¸âƒ£ Start Kafka
If using brewed Kafka:
brew services start kafka
brew services start zookeeper

3ï¸âƒ£ Run Event Producer
python producer/produce_events.py
Events will start flowing into your Kafka topic.

4ï¸âƒ£ Start Spark Streaming Job (Bronze ingestion)
python spark-jobs/streaming/stream_to_bronze.py
This writes raw events into:
delta-lake/bronze

5ï¸âƒ£ Initialize Airflow
cd unified-sales-analytics
source airflow-venv/bin/activate
export AIRFLOW_HOME=$(pwd)/airflow
airflow db migrate
airflow webserver -p 8080
airflow scheduler

Open Airflow UI:
ğŸ‘‰ http://localhost:8080
User: admin
Pass: 12345
Enable the DAG:
sales_batch_pipeline
Run it manually or wait for daily schedule.

6ï¸âƒ£ Verify Gold metrics
python spark-jobs/batch/gold_to_postgres.py
Check data:
psql -h localhost -U $USER -d unified_sales_analytics
SELECT * FROM sales_daily_metrics;

7ï¸âƒ£ Dashboard in Grafana
Open Grafana:
ğŸ‘‰ http://localhost:3000
Login: admin / admin
Add PostgreSQL Data Source:
Host: localhost
Port: 5432
Database: unified_sales_analytics
User: <your mac username>
Create dashboard panels:
Revenue Trend (gross_revenue)
Order Count Trend (order_count)
Average Order Value
KPIs

ğŸ“ˆ Example KPIs
Date	Revenue	Orders	AOV
2025-12-15	61030.83	239	255

ğŸ§ª Key Features
âœ”ï¸ End-to-end orchestration
Airflow runs the entire chain daily.
âœ”ï¸ Fully modular Spark jobs
Clear separation between Bronze, Silver, Gold.
âœ”ï¸ Enterprise-level Lakehouse
Delta ACID tables with schema tracking.
âœ”ï¸ Real-time + batch hybrid
âœ”ï¸ Grafana dashboards
Perfect for business stakeholders.

ğŸ Conclusion
This project showcases the full lifecycle of modern data engineering, including:
Real-time ingestion
Lakehouse modeling
ELT pipelines
Orchestration
Data warehousing
BI dashboards
